{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import re\n",
    "# -*- coding:utf-8 -*- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA训练集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 证据等级\n",
    "col_name = \"证据等级\"\n",
    "col_ab = \"evi\"\n",
    "que_d = {\"1\":\"Where is pathogen isolated?\"}\n",
    "\n",
    "# 免疫状态\n",
    "col_name = \"免疫状态\"\n",
    "col_ab = \"immu\"\n",
    "que_d = {\"1\":\"What's patients immunity state?\"}\n",
    "\n",
    "# 人数\n",
    "col_name = \"样本量\"\n",
    "col_ab = \"number\"\n",
    "que_d = {\"1\":\"How many patients are ivolved in this study?\"}\n",
    "\n",
    "# 性别\n",
    "col_name = \"性别\"\n",
    "col_ab = \"gender\"\n",
    "que_d = {\"1\":\"What's gender of the patient?\"}\n",
    "# 年龄\n",
    "col_name = \"年龄\"\n",
    "col_ab = \"age\"\n",
    "que_d = {\"1\":\"How old is patient?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sped_path = \"../5.Orgnize/文献标注-校对/\"\n",
    "sped_l = [ele for ele in os.listdir(sped_path) if 'more' in ele]\n",
    "txt_path = \"../4.Label_prepare/paper_ld_old/\"\n",
    "train_qa = []\n",
    "\n",
    "for sped in sped_l:\n",
    "\n",
    "    # 读取标注信息\n",
    "    print(sped)\n",
    "    df = pd.read_excel(\"%s/%s\" % (sped_path, sped), header=0)\n",
    "    df = df.loc[df[\"是否是致病菌\"] == \"是\",:]\n",
    "\n",
    "    # 读取标题和摘要的列用于后续添加标题和摘要\n",
    "    df[\"Full\"] = 0\n",
    "\n",
    "    for idx in df.index.tolist():\n",
    "\n",
    "        with open(\"%s/%s/%s.txt\" % (txt_path, sped.split(\"_\")[0], df.loc[idx, \"ID\"])) as f:\n",
    "            txt = f.read()\n",
    "        df.loc[idx, \"Full\"] = txt\n",
    "\n",
    "        # 创建WHAT Question样本\n",
    "        if np.isnan(df.loc[idx,\"%s_old_start\" % col_ab]) == False:\n",
    "            if type(df.loc[idx,\"%s_answer\" % col_ab]) == float:\n",
    "                df.loc[idx,\"%s_answer\" % col_ab] = \"NaN\"\n",
    "            if df.loc[idx, \"%s_old_start\" % col_ab] < len(df.loc[idx, \"Full\"]):\n",
    "                qa = {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"id\": str(df.loc[idx, \"ID\"]),\n",
    "                            \"question\": que_d[\"1\"],\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": df.loc[idx, \"%s_answer\" % col_ab],\n",
    "                                    \"answer_start\": int(df.loc[idx, \"%s_old_start\" % col_ab]),\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"context\": df.loc[idx, \"Full\"]}\n",
    "                train_qa.append(qa)\n",
    "    \n",
    "    df.to_csv(\"input/input_%s/%s.csv\" % (col_ab, sped.split(\"_\")[0]), header=True, index=False)\n",
    "\n",
    "train_set = {\n",
    "    \"data\": [{\n",
    "        'paragraphs': train_qa,\n",
    "        'title': \"LungB\"\n",
    "    }],\n",
    "    \"version\": \"LungB\"\n",
    "}\n",
    "json.dump(train_set, open(\"input/input_%s/train_set.json\" % (col_ab), \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for sped in sped_l:\n",
    "\n",
    "    # 读取标注信息\n",
    "    print(sped)\n",
    "    df = pd.read_excel(\"%s/%s\" % (sped_path, sped), header=0)\n",
    "    df = df.loc[df[\"是否是致病菌\"] == \"是\",:]\n",
    "\n",
    "    # 读取标题和摘要的列用于后续添加标题和摘要\n",
    "    df[\"Full\"] = 0\n",
    "\n",
    "    for idx in df.index.tolist():\n",
    "\n",
    "        with open(\"%s/%s/%s.txt\" % (txt_path, sped.split(\"_\")[0], df.loc[idx, \"ID\"])) as f:\n",
    "            txt = f.read()\n",
    "        df.loc[idx, \"Full\"] = txt\n",
    "\n",
    "        # 创建WHAT Question样本\n",
    "        if np.isnan(df.loc[idx,\"%s_old_start\" % col_ab]) == False:\n",
    "            if type(df.loc[idx,\"%s_answer\" % col_ab]) == float:\n",
    "                df.loc[idx,\"%s_answer\" % col_ab] = \"NaN\"\n",
    "            if df.loc[idx, \"%s_old_start\" % col_ab] < len(df.loc[idx, \"Full\"]):\n",
    "                qa = {\n",
    "                    \"qas\": [\n",
    "                        {\n",
    "                            \"id\": str(df.loc[idx, \"ID\"]),\n",
    "                            \"question\": que_d[\"1\"],\n",
    "                            \"answers\": [\n",
    "                                {\n",
    "                                    \"text\": df.loc[idx, \"%s_answer\" % col_ab],\n",
    "                                    \"answer_start\": int(df.loc[idx, \"%s_old_start\" % col_ab]),\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"context\": df.loc[idx, \"Full\"]}\n",
    "                train_qa.append(qa)\n",
    "    \n",
    "    df.to_csv(\"input/input_%s/%s.csv\" % (col_ab, sped.split(\"_\")[0]), header=True, index=False)\n",
    "\n",
    "train_set = {\n",
    "    \"data\": [{\n",
    "        'paragraphs': train_qa,\n",
    "        'title': \"LungB\"\n",
    "    }],\n",
    "    \"version\": \"LungB\"\n",
    "}\n",
    "json.dump(train_set, open(\"input/input_%s/train_set.json\" % (col_ab), \"w\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = json.load(open(\"output/predictions_.json\", 'r'))\n",
    "result = {}\n",
    "for i in prediction.keys():\n",
    "    toke = i.split(\":\")[0]\n",
    "    species = \"\"\n",
    "    for j in toke.split(\"_\")[0:-1]:\n",
    "        species = species + \" \" + j\n",
    "    ncbi = \"https://pubmed.ncbi.nlm.nih.gov/%s/\" % toke.split(\"_\")[-1]\n",
    "\n",
    "    result[toke] = [toke.split(\"_\")[-1], species, prediction[i][1][0], ncbi]\n",
    "    \n",
    "result = pd.DataFrame(result, index = [\"ID\", \"SPECIES\", \"rate\", \"link\"]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anaerobic\n",
      "Curved\n",
      "GramN\n",
      "GramPc\n",
      "GramPr\n",
      "Intracellular\n"
     ]
    }
   ],
   "source": [
    "sped_path = \"../4.Label_prepare/paper_md\"\n",
    "sped_l = [ele for ele in os.listdir(sped_path) if '.' not in ele]\n",
    "\n",
    "test_qa = []\n",
    "\n",
    "for sped in sped_l:\n",
    "    \n",
    "    df = pd.DataFrame(np.zeros((0,2)), columns = [\"SPECIES\", \"Full\"])\n",
    "    \n",
    "    id_l = [ele for ele in os.listdir(\"%s/%s\" % (sped_path, sped)) if 'txt' in ele]\n",
    "    id_l = [ele for ele in id_l if ele.replace(\".txt\", \"\") in result.index]\n",
    "\n",
    "    for idx in id_l:\n",
    "\n",
    "        if result.loc[idx.replace(\".txt\", \"\"), \"rate\"] > 0.5:\n",
    "        \n",
    "            with open(\"%s/%s/%s\" % (sped_path, sped, idx)) as f:\n",
    "                txt0 = f.readlines()\n",
    "            with open(\"%s/%s/%s\" % (sped_path, sped, idx)) as f:\n",
    "                txt = f.read()\n",
    "            \n",
    "            idx = idx.split(\".\")[0]\n",
    "            df.loc[idx] = [txt0[0].split(\":\")[1], txt]\n",
    "            \n",
    "            qa = {'qas': [{\n",
    "                'id': '%s:%s' % (idx, df.loc[idx, \"SPECIES\"]),\n",
    "                'question': que_d[0],\n",
    "                \"answers\": []}],\n",
    "                'context': '%s' % df.loc[idx, \"Full\"]}\n",
    "            test_qa.append(qa)\n",
    "        \n",
    "    df.to_csv(\"input/input_%s/test/%s_immu.csv\" % (col_ab, sped), header=True, index=True)\n",
    "\n",
    "test_set = {\"data\":[{'paragraphs':test_qa, 'title':\"LungB\"}], \"version\":\"LungB\"}\n",
    "\n",
    "json.dump(test_set, open(\"input/input_%s/test_set.json\" % col_ab, \"w\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "214392d51fb2c1897b3bd3ad6aaa927e6326499bab7564d3ffedfb7cce17d6fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

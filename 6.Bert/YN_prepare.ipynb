{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 函数准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import random\n",
    "from random import choice\n",
    "random.seed(10)\n",
    "# -*- coding:utf-8 -*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(standard, prediction, fig_path):\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    from itertools import cycle\n",
    "\n",
    "    from sklearn import svm, datasets\n",
    "    from sklearn.metrics import roc_curve, auc\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import label_binarize\n",
    "    from sklearn.multiclass import OneVsRestClassifier\n",
    "    from scipy import interp\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "\n",
    "    accuracy = accuracy_score(standard[\"golden\"],\n",
    "                            prediction[\"prediction\"],\n",
    "                            normalize=True,\n",
    "                            sample_weight=None)\n",
    "    precision = precision_score(standard[\"golden\"],\n",
    "                                prediction[\"prediction\"],\n",
    "                                labels=None,\n",
    "                                pos_label='yes',\n",
    "                                average='binary',\n",
    "                                sample_weight=None,\n",
    "                                zero_division='warn')\n",
    "    recall = recall_score(standard[\"golden\"],\n",
    "                        prediction[\"prediction\"],\n",
    "                        labels=None,\n",
    "                        pos_label='yes',\n",
    "                        average='binary',\n",
    "                        sample_weight=None,\n",
    "                        zero_division='warn')\n",
    "    f1 = f1_score(standard[\"golden\"],\n",
    "                prediction[\"prediction\"],\n",
    "                labels=None,\n",
    "                pos_label='yes',\n",
    "                average='binary',\n",
    "                sample_weight=None,\n",
    "                zero_division='warn')\n",
    "\n",
    "    print(\"免疫受损:\", accuracy, precision, recall, f1)\n",
    "\n",
    "    # plot roc\n",
    "    standard.loc[standard[\"golden\"] == \"yes\", \"golden\"] = 1\n",
    "    standard.loc[standard[\"golden\"] == \"no\", \"golden\"] = 0\n",
    "    standard[\"minus\"] = 1 - standard[\"golden\"]\n",
    "    standard_v = np.array(standard.values, dtype=\"float\")\n",
    "\n",
    "    prediction = prediction[[\"rate\",\"cut\"]]\n",
    "    prediction.columns = [\"golden\", \"minus\"]\n",
    "    prediction_v = np.array(prediction.values, dtype=\"float\")\n",
    "\n",
    "    # Binarize the output\n",
    "    y_test = standard_v\n",
    "    y_score = prediction_v\n",
    "    n_classes = y_score.shape[1]\n",
    "\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    for i in range(n_classes):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_score.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "    fig  = plt.figure()\n",
    "\n",
    "    plt.plot(fpr[0], tpr[0], color='darkorange',\n",
    "            lw=2, label='ROC curve (area = %0.2f)' % roc_auc[0])\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('REPEAT%s ROC curve' % re)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "    fig.savefig(\"%s/roc_curve.png\" % (fig_path))\n",
    "            \n",
    "    return accuracy, precision, recall, f1\n",
    "    \n",
    "def mk_dir(file_path):\n",
    "\n",
    "    folder = os.path.exists(file_path)\n",
    "    if not folder:\n",
    "        os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 训练集准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 判断病原菌\n",
    "col_name = \"是否是病原菌\"\n",
    "col_ab =  \"pat\"\n",
    "cla_l = [\": 是\"]\n",
    "# 临床特征现在主要使用QA方法，不适用YN方法，\n",
    "# # 判断样本量\n",
    "# col_name = \"样本量\"\n",
    "# col_ab =  \"num\"\n",
    "# cla_l = [\": 1\"]\n",
    "# # 判断免疫状态\n",
    "# col_name = \"免疫状态\"\n",
    "# col_ab =  \"immu\"\n",
    "# cla_l = [\": 是\"]\n",
    "# # 判断证据等级\n",
    "# col_name = \"证据等级\"\n",
    "# col_ab =  \"evi\"\n",
    "# cla_l = [\"1：同时具备肺组织病理+病原学证据\",\n",
    "#         \"2：肺组织病原学证据\",\n",
    "#         \"3：血及无菌体液（如脓胸液）\",\n",
    "#         \"4：气管镜活检组织培养出病原体，或者支气管肺泡灌洗液（BALF）定量培养>10**4\",\n",
    "#         \"5：气管吸出物或痰/BALF纯培养或优势培养出病原体\",\n",
    "#         \"6：气管吸出物或痰的分子诊断（PCR、基因组测序等）病原\"]\n",
    "\n",
    "# que_d = {\"1\":\"Is there lung tissue and pathogen evidence?\",\n",
    "#         \"2\":\"Is there pathogen evidence?\",\n",
    "#         \"3\":\"Is there blood or sterile body fluids evidence?\",\n",
    "#         \"4\":\"Is there bronchoscopy biopsy or BALF evidence?\",\n",
    "#         \"5\":\"Is there aspirate, sputum or BALF culture evidence?\",\n",
    "#         \"6\":\"Is there PCR or sequencing of aspirate, sputum evidence?\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sped_path = \"../5.Orgnize/文献标注-校对/\"\n",
    "sped_l = [ele for ele in os.listdir(sped_path) if 'add' in ele]\n",
    "txt_path = \"../4.Label_prepare/paper_ld\"\n",
    "\n",
    "for cla in cla_l:\n",
    "\n",
    "    train_set = {\n",
    "        \"data\": [{\n",
    "            'paragraphs': [],\n",
    "            'title': \"LungB\"\n",
    "        }],\n",
    "        \"version\": \"LungB\"\n",
    "    }\n",
    "    train_qa = []\n",
    "    im = {\"yes\": False, \"no\": True}\n",
    "\n",
    "    for sped in sped_l:\n",
    "\n",
    "        # 读取标注信息\n",
    "        df = pd.read_excel(\"%s/%s\" % (sped_path, sped), header=0)\n",
    "        df = df.loc[df[\"是否是致病菌\"] == \"是\", :]\n",
    "        \n",
    "        if col_name == \"证据等级\":\n",
    "            df.loc[df[col_name] == cla, col_name] = \"yes\"\n",
    "        else:\n",
    "            df.loc[df[col_name] == cla.split(\"：\")[0], col_name] = \"yes\"\n",
    "        \n",
    "        if col_name == \"是否是致病菌\":\n",
    "            que_d = {\"\":'Can %s cause Pneumonia?' % df.loc[idx, \"物种名称\"]}\n",
    "        if col_name == \"免疫状态\":\n",
    "            df.loc[df[col_name] == \"抑制\", col_name] = \"yes\"\n",
    "            que_d = {\"\":'Is patient immunosuppression?'}\n",
    "        df.loc[df[col_name] != \"yes\", col_name] = \"no\"\n",
    "\n",
    "        # 读取标题和摘要\n",
    "\n",
    "        df[\"Full\"] = 0\n",
    "\n",
    "        for idx in df.index.tolist():\n",
    "\n",
    "            with open(\"%s/%s/%s.txt\" % (txt_path, sped.split(\"_\")[0], df.loc[idx, \"ID\"]), \"r\") as f:\n",
    "                txt = f.read()\n",
    "            df.loc[idx, \"Full\"] = txt\n",
    "\n",
    "            # 创建QA样本\n",
    "            if df.loc[idx, col_name] in ['yes', 'no']:\n",
    "\n",
    "                # im = (df.loc[idx, \"是否是致病菌\"] != 'yes')\n",
    "                qa = {\n",
    "                    'qas': [{\n",
    "                        'id': '%s:%s' % (df.loc[idx, \"ID\"], df.loc[idx, \"物种名称\"]),\n",
    "                        'question': que_d[cla.split(\"：\")[0]],\n",
    "                        'is_impossible': im[df.loc[idx, col_name]],\n",
    "                        'answers': '%s' % df.loc[idx, col_name]\n",
    "                    }],\n",
    "                    'context':\n",
    "                    '%s' % df.loc[idx, \"Full\"]\n",
    "                }\n",
    "                train_qa.append(qa)\n",
    "        \n",
    "        mk_dir(\"input/input_%s_yn%s\" % (col_ab, cla.split(\"：\")[0]))\n",
    "        df.to_csv(\"input/input_%s_yn%s/%s.csv\" %\n",
    "                  (col_ab, cla.split(\"：\")[0], sped.split(\"_\")[0]), header=True, index=False)\n",
    "\n",
    "    train_set['data'][0][\"paragraphs\"] = train_qa\n",
    "    json.dump(train_set, open(\"input/input_%s_yn%s/train_set.json\" %\n",
    "              (col_ab, cla.split(\"：\")[0]), \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 预测集准备(现在主要功能)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预测样本格式转换\n",
    "need_selection = 0\n",
    "test_file_dir = \"Virology\"\n",
    "sped_path = \"../4.Label_prepare/%s\" % test_file_dir\n",
    "sped_l = [ele for ele in os.listdir(sped_path) if '.' not in ele]\n",
    "\n",
    "test_set = {\"data\": [{'paragraphs': [], 'title':\"LungB\"}], \"version\": \"LungB\"}\n",
    "test_qa = []\n",
    "\n",
    "for sped in sped_l:\n",
    "\n",
    "    df = pd.DataFrame(np.zeros((0, 2)), columns=[\"SPECIES\", \"Full\"])\n",
    "\n",
    "    id_l = [ele for ele in os.listdir(\n",
    "        \"%s/%s\" % (sped_path, sped))if 'txt' in ele]\n",
    "\n",
    "    for idx in id_l:\n",
    "        \n",
    "        with open(\"%s/%s/%s\" % (sped_path, sped, idx)) as f:\n",
    "            txt0 = f.readlines()\n",
    "        with open(\"%s/%s/%s\" % (sped_path, sped, idx)) as f:\n",
    "            txt = f.read()\n",
    "\n",
    "        idx = idx.split(\".\")[0]\n",
    "        df.loc[idx] = [txt0[0].split(\":\")[1], txt]\n",
    "\n",
    "        qa = {'qas': [{\n",
    "            'id': '%s:%s' % (idx, df.loc[idx, \"SPECIES\"]),\n",
    "            'question': 'Can %s cause Pneumonia?' % df.loc[idx, \"SPECIES\"]}],\n",
    "            'context': '%s' % df.loc[idx, \"Full\"]}\n",
    "        test_qa.append(qa)\n",
    "\n",
    "test_set['data'][0][\"paragraphs\"] = test_qa\n",
    "mk_dir(\"input/input_pat/%s\" % test_file_dir )\n",
    "json.dump(test_set, open(\"input/input_pat/%s/test_set.json\" % test_file_dir , \"w\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mk_dir(\"eval/evl_%s_yn\" % (col_ab, \"1\"))\n",
    "col_ab = \"evi\"\n",
    "for cla in cla_l:\n",
    "\n",
    "    train_set = json.load(open(\"input/input_%s_yn%s/train_set.json\" \\\n",
    "        %(col_ab, cla.split(\"：\")[0]), \"r\"))\n",
    "    train_qa = train_set['data'][0][\"paragraphs\"]\n",
    "    \n",
    "    for re in range(3):\n",
    "\n",
    "        eval_qa = random.sample(train_qa, int(len(train_qa) / 5))\n",
    "\n",
    "        ttrain_qa = [ele for ele in train_qa if ele not in eval_qa]\n",
    "        ttrain_set = {\n",
    "            \"data\": [{\n",
    "                'paragraphs': ttrain_qa,\n",
    "                'title': \"LungB\"\n",
    "            }],\n",
    "            \"version\": \"LungB\"\n",
    "        }\n",
    "\n",
    "        mk_dir(\"eval/evl_%s_yn%s/input%s\" % (col_ab, cla.split(\"：\")[0], re))\n",
    "        mk_dir(\"eval/evl_%s_yn%s/output%s\" % (col_ab, cla.split(\"：\")[0], re))\n",
    "\n",
    "        json.dump(ttrain_set, open(\"eval/evl_%s_yn%s/input%s/train_set.json\" \n",
    "        % (col_ab, cla.split(\"：\")[0], re), \"w\"))\n",
    "\n",
    "        eval_q=[]\n",
    "        eval_a={}\n",
    "        for i in eval_qa:\n",
    "            qq={\n",
    "                'qas': [{\n",
    "                    'id': i['qas'][0]['id'],\n",
    "                    'question': i['qas'][0]['question']\n",
    "                }],\n",
    "                'context': i['context']\n",
    "            }\n",
    "            eval_q.append(qq)\n",
    "            eval_a[i['qas'][0]['id']] = i['qas'][0]['answers']\n",
    "\n",
    "        eval_qset = {\n",
    "            \"data\": [{\n",
    "                'paragraphs': eval_q,\n",
    "                'title': \"LungB\"\n",
    "            }],\n",
    "            \"version\": \"LungB\"\n",
    "        }\n",
    "        json.dump(eval_qset, open(\"eval/evl_%s_yn%s/input%s/test_set.json\" \n",
    "        % (col_ab, cla.split(\"：\")[0], re), \"w\"))\n",
    "        json.dump(eval_a, open(\"eval/evl_%s_yn%s/input%s/eval_set.json\" \n",
    "        % (col_ab, cla.split(\"：\")[0], re), \"w\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cla_l:\n",
    "    for re in range(3):\n",
    "        eval_a = json.load(open(\"eval/evl_%s_yn%s/input%s/eval_set.json\" % (col_ab, i.split(\"：\")[0], re), \"r\"))\n",
    "        standard = pd.DataFrame(eval_a, index=[\"golden\"]).T\n",
    "        prediction = json.load(open(\"eval/evl_%s_yn%s/output%s/predictions_.json\" \n",
    "        % (col_ab, i.split(\"：\")[0], re), 'r'))\n",
    "        prediction = pd.DataFrame(prediction, index=[\"prediction\", \"rate\"]).T\n",
    "        prediction[\"cut\"] = 1\n",
    "        for idx in prediction.index:\n",
    "            prediction.loc[idx, \"rate\"] = prediction.loc[idx, \"rate\"][0]\n",
    "            prediction.loc[idx, \"cut\"] = 1 - prediction.loc[idx, \"rate\"]\n",
    "\n",
    "            if prediction.loc[idx, \"rate\"] < 0.95:\n",
    "                prediction.loc[idx, \"prediction\"] = \"no\"\n",
    "        fig_path = (\"eval/evl_%s_yn%s/output%s\" % (col_ab, i.split(\"：\")[0], re))\n",
    "\n",
    "        evaluate(standard, prediction, fig_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 组织"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sped_l = os.listdir(\"../4.Label_prepare/paper_md/\")\n",
    "for sped in sped_l:\n",
    "    spec_l = os.listdir(\"../4.Label_prepare/paper_md/%s\" % sped)\n",
    "    spec_l = [spec.replace(\".txt\", \"\") for spec in spec_l]\n",
    "    spec_tl = [spec for spec in result.index if spec in spec_l]\n",
    "    spec_yl = [spec for spec in a.index if spec in spec_l]\n",
    "#     print(sped, len(np.unique(spec_tl)), len(np.unique(spec_yl)))\n",
    "    specc_tl = [spec.split(\"_\")[0:-1] for spec in spec_tl]\n",
    "    specc_yl = [spec.split(\"_\")[0:-1] for spec in spec_yl]\n",
    "    print(sped, len(np.unique(specc_tl)), len(np.unique(specc_yl)))\n",
    "b = a[\"SPECIES\"]\n",
    "\n",
    "c = []\n",
    "for i in b:\n",
    "    spec = \"\"\n",
    "    for j in i:\n",
    "        spec = spec + \" \" + j\n",
    "        print(spec)\n",
    "        c.append(spec)\n",
    "a[\"SPECIES\"] = c.append(spec)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "214392d51fb2c1897b3bd3ad6aaa927e6326499bab7564d3ffedfb7cce17d6fb"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

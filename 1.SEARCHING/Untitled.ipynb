{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acinetobacter baumannii AND pneumonia[Mesh]\n",
      "共：1 完成：0 还剩：1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 381, in _make_request\n",
      "    self._validate_conn(conn)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 976, in _validate_conn\n",
      "    conn.connect()\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connection.py\", line 361, in connect\n",
      "    self.sock = ssl_wrap_socket(\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\util\\ssl_.py\", line 377, in ssl_wrap_socket\n",
      "    return context.wrap_socket(sock, server_hostname=server_hostname)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\ssl.py\", line 500, in wrap_socket\n",
      "    return self.sslsocket_class._create(\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\ssl.py\", line 1040, in _create\n",
      "    self.do_handshake()\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\ssl.py\", line 1309, in do_handshake\n",
      "    self._sslobj.do_handshake()\n",
      "socket.timeout: _ssl.c:1091: The handshake operation timed out\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 439, in send\n",
      "    resp = conn.urlopen(\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 724, in urlopen\n",
      "    retries = retries.increment(\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\util\\retry.py\", line 403, in increment\n",
      "    raise six.reraise(type(error), error, _stacktrace)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\packages\\six.py\", line 735, in reraise\n",
      "    raise value\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 670, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 384, in _make_request\n",
      "    self._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py\", line 335, in _raise_timeout\n",
      "    raise ReadTimeoutError(\n",
      "urllib3.exceptions.ReadTimeoutError: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=20)\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\share\\REP\\1.SEARCHING\\pubmed.py\", line 32, in download\n",
      "    response = requests.get(self.url, headers=headers, timeout=20)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\api.py\", line 76, in get\n",
      "    return request('get', url, params=params, **kwargs)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\api.py\", line 61, in request\n",
      "    return session.request(method=method, url=url, **kwargs)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 530, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\sessions.py\", line 643, in send\n",
      "    r = adapter.send(request, **kwargs)\n",
      "  File \"C:\\Users\\xinzh\\anaconda3\\lib\\site-packages\\requests\\adapters.py\", line 529, in send\n",
      "    raise ReadTimeout(e, request=request)\n",
      "requests.exceptions.ReadTimeout: HTTPSConnectionPool(host='www.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=20)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error:https://www.ncbi.nlm.nih.gov/pubmed/nanana\n",
      "HTTPSConnectionPool(host='pubmed.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=15)\n",
      "HTTPSConnectionPool(host='pubmed.ncbi.nlm.nih.gov', port=443): Read timed out. (read timeout=15)\n",
      "https://www.ncbi.nlm.nih.gov/pubmed/nanana下载失败\n",
      "Acinetobacter baumannii AND pneumonia[Mesh]共计1篇文献\n"
     ]
    }
   ],
   "source": [
    "import urllib\n",
    "import time\n",
    "from lxml import etree\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import pubmed\n",
    "import xlwt\n",
    "import openpyxl\n",
    "import compare\n",
    "\n",
    "global pmid\n",
    "pmid=[]\n",
    "class NcbiInfo(object):\n",
    "    option = webdriver.ChromeOptions()\n",
    "    option.add_argument('headless')\n",
    "    browser = webdriver.Chrome(options=option)\n",
    "    start_url = 'https://www.ncbi.nlm.nih.gov/pubmed/?term='\n",
    "    wait = WebDriverWait(browser, 10)\n",
    "\n",
    "\n",
    "    def __init__(self, keywordlist):\n",
    "        self.temp = [urllib.parse.quote(i) for i in keywordlist]\n",
    "        self.keyword = '%2C'.join(self.temp)\n",
    "        self.title = ' AND '.join(self.temp)\n",
    "        self.url = NcbiInfo.start_url + self.keyword\n",
    "        self.headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/68.0.3440.106 Safari/537.36'}\n",
    "        self.file = open('information.txt', 'w')\n",
    "        self.status = True\n",
    "        self.yearlist = []\n",
    "\n",
    "    def click_yearandabstract(self, ):\n",
    "        self.browser.get(self.url)\n",
    "        try:\n",
    "            perpage = self.wait.until(EC.element_to_be_clickable(\n",
    "                (By.XPATH, '//ul[@class=\"inline_list left display_settings\"]/li[3]/a/span[4]')))\n",
    "            perpage.click()\n",
    "            page_200 = self.wait.until(EC.element_to_be_clickable(\n",
    "                (By.CSS_SELECTOR, '#display_settings_menu_ps > fieldset > ul > li:nth-child(6) > label')))\n",
    "            page_200.click()\n",
    "        except TimeoutException:\n",
    "            self.status = False\n",
    "            pmid.append('nanana')\n",
    "\n",
    "    def get_response(self):\n",
    "        self.html = self.browser.page_source\n",
    "        self.doc = etree.HTML(self.html)\n",
    "\n",
    "    def get_info(self):\n",
    "        self.art_timeanddoi = self.doc.xpath('//div[@class=\"resc\"]/dl[@class=\"rprtid\"]/dd/text()')\n",
    "        for i in self.art_timeanddoi:\n",
    "            print(i)\n",
    "            pmid.append(i)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def next_page(self):\n",
    "        try:\n",
    "            self.nextpage = self.wait.until(\n",
    "                EC.element_to_be_clickable((By.XPATH, '//*[@title=\"Next page of results\"]')))\n",
    "        except TimeoutException:\n",
    "            self.status = False\n",
    "\n",
    "    def main(self):\n",
    "        self.click_yearandabstract()\n",
    "        time.sleep(3)\n",
    "        self.get_response()\n",
    "        while True:\n",
    "            self.get_info()\n",
    "            self.next_page()\n",
    "            if self.status:\n",
    "                self.nextpage.click()\n",
    "                self.get_response()\n",
    "            else:\n",
    "                break\n",
    "\n",
    "def savepmid(pid,key):\n",
    "    book1 = xlwt.Workbook()  # 新建一个excel\n",
    "    sheet = book1.add_sheet('case1_sheet')\n",
    "    row = 0\n",
    "    for i in pid:\n",
    "        i = \"https://www.ncbi.nlm.nih.gov/pubmed/\" + i\n",
    "        sheet.write(row, 0, i)\n",
    "        row = row + 1\n",
    "    book1.save(key + '.xlsx')\n",
    "\n",
    "def readkey(hanghao):\n",
    "   wb = openpyxl.load_workbook('search.xlsx')    # 加载工作薄\n",
    "   wb.sheetnames                                       # 获取当前所有工作表的名称， 返回一个列表\n",
    "   wb.active                                           # 获\n",
    "   sheet = wb['Sheet1']                      # 获取当前活动表的名称\n",
    "   key=sheet.cell(row=hanghao,column=1).value\n",
    "\n",
    "   return key\n",
    "\n",
    "def readrows():\n",
    "   wb = openpyxl.load_workbook('search.xlsx')  # 加载工作薄\n",
    "   wb.sheetnames  # 获取当前所有工作表的名称， 返回一个列表\n",
    "   wb.active  # 获\n",
    "   sheet = wb['Sheet1']  # 获取当前活动表的名称\n",
    "   rows = sheet.max_row\n",
    "   return rows\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hanghao = 0\n",
    "    total=[]\n",
    "    while hanghao < readrows():\n",
    "       hanghao = hanghao + 1\n",
    "       key = readkey(hanghao)  # 读取关键词\n",
    "       print(key)  # 是否读取到关键词\n",
    "       a = NcbiInfo([key])\n",
    "       a.main()\n",
    "       total.append(key+'共计'+str(len(pmid))+'篇文献')\n",
    "       savepmid(pmid,key)\n",
    "       pmid=[]\n",
    "       pubmed.abstarct(hanghao)\n",
    "       compare.compare(key)\n",
    "    for i in total:\n",
    "        print(i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

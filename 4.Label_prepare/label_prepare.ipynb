{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import packages"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import os\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import json\r\n",
    "from copy import deepcopy\r\n",
    "import re\r\n",
    "import youdao\r\n",
    "\r\n",
    "\r\n",
    "def mk_dir(file_path):\r\n",
    "\r\n",
    "    folder = os.path.exists(file_path)\r\n",
    "    if not folder:\r\n",
    "        os.makedirs(file_path)"
   ],
   "outputs": [],
   "metadata": {
    "Collapsed": "false"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# [Mesh]词的搜索结果,筛选Pubtator结果"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "source": [
    "keyword = json.load(open(\"../3.KeyWord/keyword.json\", \"r\"))\r\n",
    "input_path = \"../2.PubTator/output\"\r\n",
    "sub = [\r\n",
    "    \"BACKGROUND:\", \"BACKGROUND/AIM:\", \"METHOD:\", \"METHODS:\", \"FINGDING\",\r\n",
    "    \"FINDINGS:\", \"RESULT\", \"RESULTS:\", \"CONCLUSION\", \"CONCLUSIONS:\",\r\n",
    "    \"OBJECTIVE:\", \"OBJECTITVES\"\r\n",
    "]\r\n",
    "\r\n",
    "# 建立物种大类列表6\r\n",
    "\r\n",
    "sp_l = [ele for ele in os.listdir(input_path) if \"_done\" not in ele]\r\n",
    "sp_l = [ele for ele in sp_l if \".ipynb\" not in ele]\r\n",
    "\r\n",
    "b = []\r\n",
    "paper_ad = []\r\n",
    "for sp in sp_l:\r\n",
    "\r\n",
    "    paper_d = {}\r\n",
    "    paper_pd = {}\r\n",
    "    paper_ld = {}\r\n",
    "    paper_md = {}\r\n",
    "    paper_pld = {}\r\n",
    "    paper_pmd = {}\r\n",
    "    mk_dir(\"paper_md/%s\" % sp)\r\n",
    "    mk_dir(\"paper_ld/%s\" % sp)\r\n",
    "\r\n",
    "    # 建立这个大类中物种列表\r\n",
    "    print(sp)\r\n",
    "    spec_l = [\r\n",
    "        ele for ele in os.listdir(\"%s/%s\" % (input_path, sp))\r\n",
    "        if \".ipynb\" not in ele\r\n",
    "    ]\r\n",
    "\r\n",
    "    for spec in spec_l:\r\n",
    "\r\n",
    "        spec_d = {}  # 用于储存paper\r\n",
    "        spec_pd = {}\r\n",
    "        file_l = [\r\n",
    "            ele for ele in os.listdir(\"%s/%s/%s\" % (input_path, sp, spec))\r\n",
    "            if \".json\" in ele\r\n",
    "        ]  # 建立这个物种的三种搜索结果json文件列表\r\n",
    "\r\n",
    "        for file in file_l:\r\n",
    "\r\n",
    "            # 读取json文件中的paper并建立列表\r\n",
    "            input_name = \"%s/%s/%s/%s\" % (input_path, sp, spec, file)\r\n",
    "            data_l = json.load(open(\"%s\" % input_name, 'r'))\r\n",
    "\r\n",
    "            for paper in data_l:\r\n",
    "\r\n",
    "                # 读取pubtator的注释\r\n",
    "                title = paper[\"passages\"][0][\"text\"]\r\n",
    "                ab = paper[\"passages\"][1][\"text\"]\r\n",
    "                screen_l = keyword[\"LungRelated\"]\r\n",
    "                key_l = [\r\n",
    "                    word for word in keyword[\"LungRelated\"]\r\n",
    "                    if word in title + ab\r\n",
    "                ]\r\n",
    "\r\n",
    "                if len(key_l) > 0:  # 筛选3\r\n",
    "\r\n",
    "                    full = \"SPECIES:%s\\nID:%s\\nTITLE:%s\\nABSTRACT:%s\" % (\r\n",
    "                        spec.replace(\"_\", \" \"), paper[\"id\"], title, ab)\r\n",
    "\r\n",
    "                    # read title annotation\r\n",
    "                    title_anno = paper[\"passages\"][0][\"annotations\"]\r\n",
    "                    title_disease_l = [\r\n",
    "                        i['text'] for i in title_anno\r\n",
    "                        if i['infons']['type'] == 'Disease'\r\n",
    "                    ]\r\n",
    "                    title_species_l = [\r\n",
    "                        i['text'] for i in title_anno\r\n",
    "                        if i['infons']['type'] == 'Species'\r\n",
    "                    ]\r\n",
    "\r\n",
    "                    ab_anno = paper[\"passages\"][1][\"annotations\"]\r\n",
    "                    full_disease_l = title_disease_l + [\r\n",
    "                        i['text']\r\n",
    "                        for i in ab_anno if i['infons']['type'] == 'Disease'\r\n",
    "                    ]\r\n",
    "                    full_species_l = title_species_l + [\r\n",
    "                        i['text']\r\n",
    "                        for i in ab_anno if i['infons']['type'] == 'Species'\r\n",
    "                    ]\r\n",
    "                    pubtator_d = {}\r\n",
    "\r\n",
    "                    pubtator_d[\"dis\"] = title_disease_l + full_disease_l\r\n",
    "                    #                     pubtator_d[\"spec\"] = title_species_l + full_species_l\r\n",
    "                    pubtator_d[\"spec\"] = spec.replace(\"_\", \" \")\r\n",
    "\r\n",
    "                    for word in sub:\r\n",
    "                        if word in full:\r\n",
    "                            full = full.replace(word, \"\\n%s\" % word)\r\n",
    "                            full = full.replace(\"\\n\\n\", \"\\n\")\r\n",
    "\r\n",
    "                    spec_d[paper[\"id\"]] = full\r\n",
    "                    spec_pd[paper[\"id\"]] = pubtator_d\r\n",
    "\r\n",
    "        paper_d[spec] = spec_d\r\n",
    "        paper_pd[spec] = spec_pd\r\n",
    "    paper_ad.append(paper_d)\r\n",
    "    a = []\r\n",
    "    for specc in paper_d:\r\n",
    "        if len(paper_d[specc]) >= 10:\r\n",
    "            if len(paper_d[specc]) > 0:\r\n",
    "                for paperr in paper_d[specc]:\r\n",
    "                    a.append([int(paperr), specc.replace(\"_\", \" \")])\r\n",
    "                    with open(\r\n",
    "                            \"%s/%s/%s.txt\" %\r\n",
    "                        (\"paper_ld\", sp, specc + \"_\" + paperr), \"w\") as f:\r\n",
    "                        f.write(paper_d[specc][paperr])\r\n",
    "    b.append(a)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Anaerobic\n",
      "Curved\n",
      "GramN\n",
      "GramPc\n",
      "GramPr\n",
      "Intracellular\n"
     ]
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Add species which are overwritting by same paper"
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "c = []\r\n",
    "for sp in sp_l:\r\n",
    "    d = pd.read_excel(\"文献标注—校对/%s.xls\" % sp, index_col=0, header=0)\r\n",
    "    d[\"ID\"] = d.index\r\n",
    "    d = d.loc[:, [\"ID\", \"物种名称\"]]\r\n",
    "    d = d.values.tolist()\r\n",
    "    c.append(d)\r\n",
    "\r\n",
    "# f = []\r\n",
    "# for i  in range(len(b)):\r\n",
    "#     e = []\r\n",
    "#     for j in range(len(b[i])):\r\n",
    "#         if b[i][j] not in c[i]:\r\n",
    "#             print(b[i][j])\r\n",
    "#             e.append(b[i][j])\r\n",
    "#     print(len(c[i]), len(b[i]))\r\n",
    "#     print(len(e))\r\n",
    "#     f.append(e)\r\n",
    "\r\n",
    "# for i in range(len(sp_l)):\r\n",
    "#     d = pd.read_excel(\"文献标注—校对/%s.xls\" % sp_l[i], index_col=0, header=0)\r\n",
    "#     d[\"ID\"] = d.index\r\n",
    "#     g = pd.DataFrame(f[i], columns = [\"ID\", \"物种名称\"] )\r\n",
    "#     print(g.shape)\r\n",
    "#     df = pd.concat([d, g], axis=0)\r\n",
    "#     for j in df.index:\r\n",
    "#         df.loc[j, \"id\"] = \"https://pubmed.ncbi.nlm.nih.gov/%s/\" % df.loc[j, \"ID\"]\r\n",
    "#     df.to_excel(\"%s.xls\" % (sp_l[i] + \"_add\"))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 添加翻译（真贵！！！）"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "input_path = \"XY\"\r\n",
    "sped_l = os.listdir(input_path)\r\n",
    "keyword = json.load(open(\"../3.KeyWord/keyword.json\", \"r\"))\r\n",
    "\r\n",
    "for sped in sped_l:\r\n",
    "\r\n",
    "    mk_dir(\"paper_ld/%s/input\" % sped)\r\n",
    "\r\n",
    "    paper_l = os.listdir(\"%s/%s/outputs\" % (input_path, sped))\r\n",
    "    paper_l = [ele for ele in paper_l if \"ipynb\" not in ele]\r\n",
    "\r\n",
    "    for paper in paper_l:\r\n",
    "\r\n",
    "        # 添加翻译\r\n",
    "        folder = os.path.exists(\"paper_ldcn/%s/%s\" % (sped, paper))\r\n",
    "\r\n",
    "        if not folder:\r\n",
    "\r\n",
    "            with open(\"%s/%s/%s\" % (input_path, sped, paper), \"r\") as f:\r\n",
    "                full = f.read()\r\n",
    "                f.close()\r\n",
    "            if len(full) > 5000:\r\n",
    "                full_1 = full[0:5000]\r\n",
    "                full_2 = full[5000:len(full)]\r\n",
    "\r\n",
    "                full1_cn = youdao.youdao_trans(full_1)\r\n",
    "                full2_cn = youdao.youdao_trans(full_2)\r\n",
    "                full_t = full + \"\\n\" + full1_cn + full2_cn\r\n",
    "            else:\r\n",
    "                full_cn = youdao.youdao_trans(full)\r\n",
    "                full_t = full + \"\\n\" + full_cn\r\n",
    "            with open(\"paper_ldcn/%s/%s\" % (sped, paper), \"w\") as f:\r\n",
    "                f.write(full_t)\r\n",
    "                f.close()\r\n",
    "\r\n",
    "        with open(\r\n",
    "                \"%s/%s/%s_pubtator.json\" %\r\n",
    "            (input_path, sped, paper.replace(\".json\", \"\")), \"r\") as f:\r\n",
    "            pubtator_d = json.load(f)\r\n",
    "            dis_l = pubtator_d[\"dis\"]\r\n",
    "            rm_l = [\r\n",
    "                \"infection\", \"infections\", \"infect\", \"Infection\", \"Infections\",\r\n",
    "                \"Infect\"\r\n",
    "            ]\r\n",
    "            dis_l = [ele for ele in dis_l if ele not in rm_l]\r\n",
    "            sp_l = pubtator_d[\"spec\"]\r\n",
    "            f.close()\r\n",
    "        keyword[\"DISEASE\"] = np.unique(dis_l)\r\n",
    "        keyword[\"SPECIES\"] = np.unique(sp_l)\r\n",
    "        with open(\"%s/%s/outputs/%s\" % (input_path, sped, paper), \"r\") as f:\r\n",
    "            txt = json.load(f)\r\n",
    "            full = txt['content']\r\n",
    "            f.close()\r\n",
    "\r\n",
    "        anot = {\r\n",
    "            'type': 'T',\r\n",
    "            'name': '',\r\n",
    "            'value': '',\r\n",
    "            'start': 0,\r\n",
    "            'end': 0,\r\n",
    "            'attributes': [],\r\n",
    "            'id': 1\r\n",
    "        }\r\n",
    "        anoa = {'annotation': {'T': [''], 'E': [''], 'R': [''], 'A': ['']}}\r\n",
    "\r\n",
    "        for pre_type in keyword.keys():\r\n",
    "            anot[\"name\"] = pre_type\r\n",
    "            for word in keyword[pre_type]:\r\n",
    "                if word in full:\r\n",
    "                    anot[\"value\"] = word\r\n",
    "                    for m in re.finditer(\r\n",
    "                            word.replace(\")\", \" \").replace(\"(\", \" \"),\r\n",
    "                            full.replace(\"\\n\",\r\n",
    "                                         \"\").replace(\")\",\r\n",
    "                                                     \" \").replace(\"(\", \" \")):\r\n",
    "                        anot[\"start\"] = m.start()\r\n",
    "                        anot[\"end\"] = m.end()\r\n",
    "                        anot[\"id\"] = len(anoa[\"annotation\"][\"T\"])\r\n",
    "                        guodu = deepcopy(anot)\r\n",
    "                        anoa[\"annotation\"][\"T\"].append(guodu)\r\n",
    "        txt[\"outputs\"] = anoa\r\n",
    "        txt[\"labeled\"] = \"true\"\r\n",
    "\r\n",
    "#         with open(\"%s/%s/input/%s\" % (input_path, sped, paper), \"w\") as f:\r\n",
    "#             b = json.dumps(txt)\r\n",
    "#             f.write(b)"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'XY/GramN/outputs'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-6d34d5935e67>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmk_dir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"paper_ld/%s/input\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0msped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mpaper_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s/%s/outputs\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minput_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msped\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mpaper_l\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mele\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mele\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaper_l\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"ipynb\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mele\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'XY/GramN/outputs'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "input_path = \"XY\"\n",
    "paper_l = os.listdir(input_path)\n",
    "import youdao\n",
    "\n",
    "for paper in paper_l:\n",
    "\n",
    "    # 添加翻译\n",
    "\n",
    "    with open(\"%s/%s\" % (input_path, paper), \"r\") as f:\n",
    "        full = f.read()\n",
    "        f.close()\n",
    "    if len(full) > 5000:\n",
    "        full_1 = full[0:5000]\n",
    "        full_2 = full[5000:len(full)]\n",
    "\n",
    "        full1_cn = youdao.youdao_trans(full_1)\n",
    "        full2_cn = youdao.youdao_trans(full_2)\n",
    "        full_t = full + \"\\n\" + full1_cn + full2_cn\n",
    "    else:\n",
    "        full_cn = youdao.youdao_trans(full)\n",
    "        full_t = full + \"\\n\" + full_cn\n",
    "    with open(\"XY_CN/%s\" % (paper), \"w\") as f:\n",
    "        f.write(full_t)\n",
    "        f.close()\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyError",
     "evalue": "'translation'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-77225f7cd856>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mfull_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfull1_cn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfull2_cn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0mfull_cn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0myoudao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myoudao_trans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mfull_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfull\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfull_cn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"XY_CN/%s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpaper\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\share\\REP\\4.Label_prepare\\youdao.py\u001b[0m in \u001b[0;36myoudao_trans\u001b[1;34m(translate_text)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myoudao_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# 获取返回的json()内容\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"translation\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m   \u001b[1;31m# 获取翻译内容\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'translation'"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from copy import deepcopy\n",
    "import re\n",
    "import youdao\n",
    "\n",
    "\n",
    "def mk_dir(file_path):\n",
    "\n",
    "    folder = os.path.exists(file_path)\n",
    "    if not folder:\n",
    "        os.makedirs(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Mesh]词的搜索结果,筛选Pubtator结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec_cob\n"
     ]
    }
   ],
   "source": [
    "keyword = json.load(open(\"../3.KeyWord/keyword.json\", \"r\"))\n",
    "input_path = \"../2.PubTator/output/Virology/\"\n",
    "file_dir = \"Virology\"\n",
    "sub = [\n",
    "    \"BACKGROUND:\", \"BACKGROUND/AIM:\", \"METHOD:\", \"METHODS:\", \"FINGDING\",\n",
    "    \"FINDINGS:\", \"RESULT\", \"RESULTS:\", \"CONCLUSION\", \"CONCLUSIONS:\",\n",
    "    \"OBJECTIVE:\", \"OBJECTITVES\"\n",
    "]\n",
    "\n",
    "# 建立物种大类列表6\n",
    "\n",
    "sp_l = [ele for ele in os.listdir(input_path) if \"_done\" not in ele]\n",
    "sp_l = [ele for ele in sp_l if \".ipynb\" not in ele]\n",
    "\n",
    "b = []\n",
    "paper_ad = []\n",
    "for sp in sp_l:\n",
    "\n",
    "    paper_d = {}\n",
    "    paper_pd = {}\n",
    "    paper_ld = {}\n",
    "    paper_md = {}\n",
    "    paper_pld = {}\n",
    "    paper_pmd = {}\n",
    "    mk_dir(\"%s/%s\" % (file_dir, sp))\n",
    "\n",
    "    # 建立这个大类中物种列表\n",
    "    print(sp)\n",
    "    spec_l = [\n",
    "        ele for ele in os.listdir(\"%s/%s\" % (input_path, sp))\n",
    "        if \".ipynb\" not in ele\n",
    "    ]\n",
    "\n",
    "    for spec in spec_l:\n",
    "\n",
    "        spec_d = {}  # 用于储存paper\n",
    "        spec_pd = {}\n",
    "        file_l = [\n",
    "            ele for ele in os.listdir(\"%s/%s/%s\" % (input_path, sp, spec))\n",
    "            if \".json\" in ele\n",
    "        ]  # 建立这个物种的三种搜索结果json文件列表\n",
    "\n",
    "        for file in file_l:\n",
    "\n",
    "            # 读取json文件中的paper并建立列表\n",
    "            input_name = \"%s/%s/%s/%s\" % (input_path, sp, spec, file)\n",
    "            data_l = json.load(open(\"%s\" % input_name, 'r'))\n",
    "\n",
    "            for paper in data_l:\n",
    "\n",
    "                # 读取pubtator的注释\n",
    "                title = paper[\"passages\"][0][\"text\"]\n",
    "                ab = paper[\"passages\"][1][\"text\"]\n",
    "                screen_l = keyword[\"LungRelated\"]\n",
    "                key_l = [\n",
    "                    word for word in keyword[\"LungRelated\"]\n",
    "                    if word in title + ab\n",
    "                ]\n",
    "\n",
    "                if len(key_l) > 0:  # 筛选3\n",
    "\n",
    "                    full = \"SPECIES:%s\\nID:%s\\nTITLE:%s\\nABSTRACT:%s\" % (\n",
    "                        spec.replace(\"_\", \" \"), paper[\"id\"], title, ab)\n",
    "\n",
    "                    # read title annotation\n",
    "                    title_anno = paper[\"passages\"][0][\"annotations\"]\n",
    "                    title_disease_l = [\n",
    "                        i['text'] for i in title_anno\n",
    "                        if i['infons']['type'] == 'Disease'\n",
    "                    ]\n",
    "                    title_species_l = [\n",
    "                        i['text'] for i in title_anno\n",
    "                        if i['infons']['type'] == 'Species'\n",
    "                    ]\n",
    "\n",
    "                    ab_anno = paper[\"passages\"][1][\"annotations\"]\n",
    "                    full_disease_l = title_disease_l + [\n",
    "                        i['text']\n",
    "                        for i in ab_anno if i['infons']['type'] == 'Disease'\n",
    "                    ]\n",
    "                    full_species_l = title_species_l + [\n",
    "                        i['text']\n",
    "                        for i in ab_anno if i['infons']['type'] == 'Species'\n",
    "                    ]\n",
    "                    pubtator_d = {}\n",
    "\n",
    "                    pubtator_d[\"dis\"] = title_disease_l + full_disease_l\n",
    "                    #                     pubtator_d[\"spec\"] = title_species_l + full_species_l\n",
    "                    pubtator_d[\"spec\"] = spec.replace(\"_\", \" \")\n",
    "\n",
    "                    for word in sub:\n",
    "                        if word in full:\n",
    "                            full = full.replace(word, \"\\n%s\" % word)\n",
    "                            full = full.replace(\"\\n\\n\", \"\\n\")\n",
    "\n",
    "                    spec_d[paper[\"id\"]] = full\n",
    "                    spec_pd[paper[\"id\"]] = pubtator_d\n",
    "\n",
    "        paper_d[spec] = spec_d\n",
    "        paper_pd[spec] = spec_pd\n",
    "    paper_ad.append(paper_d)\n",
    "\n",
    "    a = []\n",
    "    # for specc in paper_d:\n",
    "    #     if len(paper_d[specc]) >= 10:\n",
    "    #         if len(paper_d[specc]) > 0:\n",
    "    #             for paperr in paper_d[specc]:\n",
    "    #                 a.append([int(paperr), specc.replace(\"_\", \" \")])\n",
    "    #                 with open(\n",
    "    #                         \"%s/%s/%s.txt\" %\n",
    "    #                     (\"paper_ld\", sp, specc + \"_\" + paperr), \"w\") as f:\n",
    "    #                     f.write(paper_d[specc][paperr])\n",
    "    for specc in paper_d:\n",
    "        if len(paper_d[specc]) > 0:\n",
    "            for paperr in paper_d[specc]:\n",
    "                a.append([int(paperr), specc.replace(\"_\", \" \")])\n",
    "                with open(\n",
    "                        \"%s/%s/%s.txt\" %\n",
    "                    (file_dir, sp, specc + \"_\" + paperr), \"w\",  encoding=\"utf-8\") as f:\n",
    "                    f.write(paper_d[specc][paperr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Add species which are overwritting by same paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for sp in sp_l:\n",
    "    d = pd.read_excel(\"文献标注—校对/%s.xls\" % sp, index_col=0, header=0)\n",
    "    d[\"ID\"] = d.index\n",
    "    d = d.loc[:, [\"ID\", \"物种名称\"]]\n",
    "    d = d.values.tolist()\n",
    "    c.append(d)\n",
    "\n",
    "# f = []\n",
    "# for i  in range(len(b)):\n",
    "#     e = []\n",
    "#     for j in range(len(b[i])):\n",
    "#         if b[i][j] not in c[i]:\n",
    "#             print(b[i][j])\n",
    "#             e.append(b[i][j])\n",
    "#     print(len(c[i]), len(b[i]))\n",
    "#     print(len(e))\n",
    "#     f.append(e)\n",
    "\n",
    "# for i in range(len(sp_l)):\n",
    "#     d = pd.read_excel(\"文献标注—校对/%s.xls\" % sp_l[i], index_col=0, header=0)\n",
    "#     d[\"ID\"] = d.index\n",
    "#     g = pd.DataFrame(f[i], columns = [\"ID\", \"物种名称\"] )\n",
    "#     print(g.shape)\n",
    "#     df = pd.concat([d, g], axis=0)\n",
    "#     for j in df.index:\n",
    "#         df.loc[j, \"id\"] = \"https://pubmed.ncbi.nlm.nih.gov/%s/\" % df.loc[j, \"ID\"]\n",
    "#     df.to_excel(\"%s.xls\" % (sp_l[i] + \"_add\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 添加翻译（真贵！！！）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"XY\"\n",
    "sped_l = os.listdir(input_path)\n",
    "keyword = json.load(open(\"../3.KeyWord/keyword.json\", \"r\"))\n",
    "\n",
    "for sped in sped_l:\n",
    "\n",
    "    mk_dir(\"paper_ld/%s/input\" % sped)\n",
    "\n",
    "    paper_l = os.listdir(\"%s/%s/outputs\" % (input_path, sped))\n",
    "    paper_l = [ele for ele in paper_l if \"ipynb\" not in ele]\n",
    "\n",
    "    for paper in paper_l:\n",
    "\n",
    "        # 添加翻译\n",
    "        folder = os.path.exists(\"paper_ldcn/%s/%s\" % (sped, paper))\n",
    "\n",
    "        if not folder:\n",
    "\n",
    "            with open(\"%s/%s/%s\" % (input_path, sped, paper), \"r\") as f:\n",
    "                full = f.read()\n",
    "                f.close()\n",
    "            if len(full) > 5000:\n",
    "                full_1 = full[0:5000]\n",
    "                full_2 = full[5000:len(full)]\n",
    "\n",
    "                full1_cn = youdao.youdao_trans(full_1)\n",
    "                full2_cn = youdao.youdao_trans(full_2)\n",
    "                full_t = full + \"\\n\" + full1_cn + full2_cn\n",
    "            else:\n",
    "                full_cn = youdao.youdao_trans(full)\n",
    "                full_t = full + \"\\n\" + full_cn\n",
    "            with open(\"paper_ldcn/%s/%s\" % (sped, paper), \"w\") as f:\n",
    "                f.write(full_t)\n",
    "                f.close()\n",
    "\n",
    "        with open(\n",
    "                \"%s/%s/%s_pubtator.json\" %\n",
    "            (input_path, sped, paper.replace(\".json\", \"\")), \"r\") as f:\n",
    "            pubtator_d = json.load(f)\n",
    "            dis_l = pubtator_d[\"dis\"]\n",
    "            rm_l = [\n",
    "                \"infection\", \"infections\", \"infect\", \"Infection\", \"Infections\",\n",
    "                \"Infect\"\n",
    "            ]\n",
    "            dis_l = [ele for ele in dis_l if ele not in rm_l]\n",
    "            sp_l = pubtator_d[\"spec\"]\n",
    "            f.close()\n",
    "        keyword[\"DISEASE\"] = np.unique(dis_l)\n",
    "        keyword[\"SPECIES\"] = np.unique(sp_l)\n",
    "        with open(\"%s/%s/outputs/%s\" % (input_path, sped, paper), \"r\") as f:\n",
    "            txt = json.load(f)\n",
    "            full = txt['content']\n",
    "            f.close()\n",
    "\n",
    "        anot = {\n",
    "            'type': 'T',\n",
    "            'name': '',\n",
    "            'value': '',\n",
    "            'start': 0,\n",
    "            'end': 0,\n",
    "            'attributes': [],\n",
    "            'id': 1\n",
    "        }\n",
    "        anoa = {'annotation': {'T': [''], 'E': [''], 'R': [''], 'A': ['']}}\n",
    "\n",
    "        for pre_type in keyword.keys():\n",
    "            anot[\"name\"] = pre_type\n",
    "            for word in keyword[pre_type]:\n",
    "                if word in full:\n",
    "                    anot[\"value\"] = word\n",
    "                    for m in re.finditer(\n",
    "                            word.replace(\")\", \" \").replace(\"(\", \" \"),\n",
    "                            full.replace(\"\\n\",\n",
    "                                         \"\").replace(\")\",\n",
    "                                                     \" \").replace(\"(\", \" \")):\n",
    "                        anot[\"start\"] = m.start()\n",
    "                        anot[\"end\"] = m.end()\n",
    "                        anot[\"id\"] = len(anoa[\"annotation\"][\"T\"])\n",
    "                        guodu = deepcopy(anot)\n",
    "                        anoa[\"annotation\"][\"T\"].append(guodu)\n",
    "        txt[\"outputs\"] = anoa\n",
    "        txt[\"labeled\"] = \"true\"\n",
    "\n",
    "#         with open(\"%s/%s/input/%s\" % (input_path, sped, paper), \"w\") as f:\n",
    "#             b = json.dumps(txt)\n",
    "#             f.write(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"XY\"\n",
    "paper_l = os.listdir(input_path)\n",
    "import youdao\n",
    "\n",
    "for paper in paper_l:\n",
    "\n",
    "    # 添加翻译\n",
    "\n",
    "    with open(\"%s/%s\" % (input_path, paper), \"r\") as f:\n",
    "        full = f.read()\n",
    "        f.close()\n",
    "    if len(full) > 5000:\n",
    "        full_1 = full[0:5000]\n",
    "        full_2 = full[5000:len(full)]\n",
    "\n",
    "        full1_cn = youdao.youdao_trans(full_1)\n",
    "        full2_cn = youdao.youdao_trans(full_2)\n",
    "        full_t = full + \"\\n\" + full1_cn + full2_cn\n",
    "    else:\n",
    "        full_cn = youdao.youdao_trans(full)\n",
    "        full_t = full + \"\\n\" + full_cn\n",
    "    with open(\"XY_CN/%s\" % (paper), \"w\") as f:\n",
    "        f.write(full_t)\n",
    "        f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
